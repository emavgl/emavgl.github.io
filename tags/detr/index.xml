<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>DETR on Emanuele Viglianisi</title><link>https://emavgl.github.io/tags/detr/</link><description>Recent content in DETR on Emanuele Viglianisi</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Tue, 02 Aug 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://emavgl.github.io/tags/detr/index.xml" rel="self" type="application/rss+xml"/><item><title>Comparing a transformer-based detector with a classical detector</title><link>https://emavgl.github.io/posts/third-blog/</link><pubDate>Tue, 02 Aug 2022 00:00:00 +0000</pubDate><guid>https://emavgl.github.io/posts/third-blog/</guid><description>Table Of Contents 🔥 Motivation 🔫 Dataset Description 🔩 Set-Up 🩺Results 👍 Coco Metric CNN 👍 Coco Metric Transformers 🙏 Comments &amp;amp; Feedback Follow me 👇 🔥 Motivation Link to heading Since the introduction, by Facebook, Transformer based detectors are getting a lot of traction in Computer Vision and Object Detection.
In this blog, I will show how a partially trained detector using SWIN transformer backbone leads to a very competitive performance compared to a fully trained classical detector.</description></item></channel></rss>