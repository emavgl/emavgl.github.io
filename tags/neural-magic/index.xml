<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Neural Magic on Emanuele Viglianisi</title><link>https://emavgl.github.io/tags/neural-magic/</link><description>Recent content in Neural Magic on Emanuele Viglianisi</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Fri, 16 Sep 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://emavgl.github.io/tags/neural-magic/index.xml" rel="self" type="application/rss+xml"/><item><title>YoloV5 Deployment Optimization with Neural Magic</title><link>https://emavgl.github.io/posts/second-blog/</link><pubDate>Fri, 16 Sep 2022 00:00:00 +0000</pubDate><guid>https://emavgl.github.io/posts/second-blog/</guid><description>Table Of Contents ğŸ”¥ Motivation: ğŸ”« What: ğŸš’ Why: â›³ How: ğŸ”© Setting Up Table Resume Prediction Speed Metrics Test Set F1 Score Sample of video annotation ğŸ™ Comments &amp;amp; Feedback Follow me ğŸ‘‡ ğŸ”¥ Motivation: Link to heading As architecture get more complex, for improved prediction results, the generated model are larger and larger, therefore the need to reduce their size and allow the model to run prediction on CPU.</description></item></channel></rss>